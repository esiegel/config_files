# uncomment to profile zsh loading
# after shell loads run `zprof`
# zmodload zsh/zprof

# add custom zsh function dir
# Must go on top.
fpath+=~/.zfunc

############## OH_MY_ZSH INIT

ZSH=$HOME/.oh-my-zsh
ZSH_THEME="robbyrussell"

DISABLE_AUTO_UPDATE="true"

# homebrew prefix
HB=$(brew --prefix)

# Need to set default python before sourcing oh my zsh
export PATH="$HB/opt/python@3/libexec/bin:$HOME/Library/Python/3.10/bin:$PATH"

# Need to set virtualenv default home before plugins
export WORKON_HOME="~/.virtualenvs"
export VIRTUALENVWRAPPER_PYTHON="$HB/bin/python3"

# Custom plugins may be added to ~/.oh-my-zsh/custom/plugins/
plugins=(git-extras pip virtualenvwrapper golang)

# Smarter completion initialization - only recalculate completion every so often
autoload -Uz compinit
if [ "$(date +'%j')" != "$(stat -f '%Sm' -t '%j' ~/.zcompdump 2>/dev/null)" ]; then
    compinit
else
    compinit -C
fi

# oh-my-zsh entry
source $ZSH/oh-my-zsh.sh

############## ZSH CONFIG

export PATH="$PATH:$HB/bin:$HB/sbin:/usr/local/bin:/usr/local/sbin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/scripts:/opt/bin"

# Direnv hook for loading directory environments
# Setting an empty log format prevents logging.
eval "$(direnv hook zsh)"
export DIRENV_LOG_FORMAT=""

# Increase cmd history size
export HISTSIZE=12000

# don't ask if "this is correct"
unsetopt correct_all
unsetopt correct

# set editor variables
export EDITOR=$(which nvim)
export PAGER=less

# Less needs to pass through escaped color characters.
export LESS=-R

# location for XDG config files, for example git will look here
export XDG_CONFIG_HOME=$HOME/.config

CODE=$HOME/code

if [[ -d $HOME/Dropbox ]]; then
   export DROPBOX=$HOME/Dropbox
elif [[ -d "$HOME/Dropbox (Personal)" ]]; then
   export DROPBOX="$HOME/Dropbox (Personal)"
elif [[ -d "$HOME/Library/CloudStorage/Box-Box" ]]; then
   export DROPBOX="$HOME/Documents/dropbox_local"
fi

# load custom source
if [[ -f $HOME/.zshrc-custom ]]; then
   source $HOME/.zshrc-custom
fi

# load all files in .zsh_files
for file in ~/.zsh_files/*(DN); do
  source "$file"
done

# allow CTRL-x-e to edit the command line in $EDITOR
autoload edit-command-line
zle -N edit-command-line
bindkey '^Xe' edit-command-line

############## NODE

# Add Node modules to path
export PATH=$PATH:/usr/local/share/npm/bin

############## Haskell

# add haskell cabal binaries to path
export PATH=$PATH:$HOME/.cabal/bin

# cabal uninstall
cabal-uninstall() {
   if [[ $# -ne 1 ]]; then
       echo cabal-uninstall: need to speicify package to uninstall
       return 1
   fi
   package=$1
   ghc-pkg unregister $package >/dev/null 2>&1
   find ~/.cabal -type d -name "*$package*" | xargs rm -rf
   find ~/.cabal -type f -name "*$package*" | xargs rm
}

################## GOLANG

export PATH="$HB/opt/go@1.24/bin:$PATH"

export GOPATH=$CODE/go
export GOBIN=$GOPATH/bin
export PATH=$PATH:$GOPATH/bin

# required for new clang to by default search
export CGO_LDFLAGS="-L$HB/lib"


go_build_multi() {
  local main_path="$1"
  local output_name="$2"

  local osx_arm_out="$2_osx_arm"
  local osx_amd_out="$2_osx_amd"
  local linux_out="$2_linux"
  local windows_out="$2_windows"

  echo "Building ARM64 OSX: $1 -> $osx_arm_out"
  GOOS=darwin  GOARCH=arm64 go build -o "$osx_arm_out" "$1" || exit 1
  echo "Building AMD64 OSX: $1 -> $osx_amd_out"
  GOOS=darwin  GOARCH=amd64 go build -o "$osx_amd_out" "$1" || exit 1
  echo "Building LINUX: $1 -> $linux_out"
  GOOS=linux   GOARCH=amd64 go build -o "$linux_out" "$1" || exit 1
  echo "Building WINDOWS: $1 -> $windows_out"
  GOOS=windows GOARCH=amd64 go build -o "$windows_out" "$1" || exit 1

  # create a tar.gz file
  tar -cvzf "$2.tar.gz" "$osx_arm_out" "$osx_amd_out" "$linux_out" "$windows_out"
}

# Creates a git patch, and runs golangci-lint
# should be run at the root of the repo
golangci_from_patch() {
  git diff main > /tmp/golangci.patch
  golangci-lint run --output.text.print-issued-lines=false --issues-exit-code=0 --max-issues-per-linter=0 --max-same-issues=0 --show-stats=false --new-from-patch=/tmp/golangci.patch
}

golangci_all() {
  golangci-lint run --output.text.print-issued-lines=false --issues-exit-code=0 --max-issues-per-linter=0 --max-same-issues=0 --show-stats=false ./...
}

################## GITHUB
# echo to stderr
log() {
  echo "$@" >&2
}

function gh_review_comments() {
  url=$(gh pr view --json url | jq '.url' | tr -d '"')
  owner=$(echo "$url" | cut -d '/' -f 4)
  name=$(echo "$url" | cut -d '/' -f 5)
  pr=$(echo "$url" | cut -d '/' -f 7)

  log "OWNER" $owner
  log "name" $name
  log "pr" $pr

  gh api graphql -F owner="$owner" -F name="$name" -F pr="$pr" \
  -f query='
  query($name: String!, $owner: String!, $pr: Int!) {
    repository(owner: $owner, name: $name) {
      pullRequest(number: $pr) {
        reviewThreads(first: 100) {
          nodes {
            comments(first: 100) {
              nodes {
                author{login} body createdAt
              }
            }
          }
        }
      }
    }
  }'
}

# Converts an ISO_8601 data to a string like 8 hours ago
function time_since() {
  local input_date="$1"

  if [[ -z "$input_date" ]]; then
    log "Usage: time_since <ISO_8601_Date>"
    return 1
  fi

  # Convert the input date to a Unix timestamp
  local input_timestamp
  input_timestamp=$(date -j -u -f "%Y-%m-%dT%H:%M:%SZ" "$input_date" "+%s" 2>/dev/null)


  # Handle invalid date input
  if [[ -z "$input_timestamp" ]]; then
    log "Error: Invalid date format. Please use ISO 8601 format (e.g., 2024-12-19T15:43:46Z)."
    return 1
  fi

  # Get the current timestamp
  local current_timestamp
  current_timestamp=$(date +%s)

  # Calculate the difference in seconds
  local difference
  difference=$((current_timestamp - input_timestamp))

  # Convert the difference to hours and days
  local hours
  local days
  hours=$((difference / 3600))
  days=$((difference / 86400))

  # Output the result
  if [[ $hours -lt 24 ]]; then
    echo "$hours hours ago"
  else
    echo "$days days ago"
  fi
}


function gh_count_review_reqs() {
  local repo="$1"

  if [[ $repo ]]; then
    # query open review requests on specific repo
    echo "Querying: $repo"
    local data=$(gh pr list --json 'reviewRequests' --repo "$repo")
  else 
    # query open review requests on local repo in directory
    local data=$(gh pr list --json 'reviewRequests')
  fi

  echo "$data" | jq 'map(.reviewRequests) | flatten | map(.login) | .[]' | sort | uniq -c | sort -nr
}

function gh_direct_review_reqs() {
  local username=esiegel

  # will find all prs that im requested on, even those that arent direct requests, as in cloud-dev
  local gh_output
  gh_output=$(gh api graphql -f query="
  {
    search(query: \"review-requested:${username} is:pr is:open\", type: ISSUE, first: 100) {
      edges {
        node {
          ... on PullRequest {
            title
            headRefName
            createdAt
            url
            reviewRequests(first: 10) {
              nodes {
                requestedReviewer {
                  ... on User {
                    login
                  }
                }
              }
            }
          }
        }
      }
    }
  }")

  # Search all the nodes and filters those nodes where i am a direct requestee
  # Results will be a bunch of elements as such
  # [
  #   "PR_kwDOBObU4s6Fzl48",
  #   "chore(cloupe): support byte data in api requests",
  #   "jeff/bytearr-readers",
  #   "2024-12-19T15:43:46Z"
  # ]
  local nodes=$(echo "$gh_output" | jq -r ".data.search.edges[].node | select(.reviewRequests.nodes[].requestedReviewer.login == \"${username}\") | [ .title, .headRefName, .createdAt, .url ]")

  # create a tab separated header line and dash line
  local header=$(echo '[
    "title",
    "branch",
    "createdAt",
    "url"
  ]
  [
    "----",
    "----",
    "----",
    "----"
  ]' | jq -r '. | @tsv')

  # modify created at column to use a better time format
  local modified_nodes=$(echo "$nodes" | jq -r '. | @tsv' | while IFS=$'\t' read -r title branch createdAt url; do
    human_readable_date=$(time_since "$createdAt")
    printf "%s\t%s\t%s\t%s\n" "$title" "$branch" "$human_readable_date" "$url"
  done)

  # combine header and modified nodes, which should already be tab separated and align
  echo "$header\n$modified_nodes" | column -t -s $'\t'
}

# remove all local branches that no longer have a tracking branch that exists
function git_prune() {
  git fetch -p
  git branch -vv | grep ': gone]' | cut -d' ' -f 3 | xargs git branch -D
}

################## RUST

export PATH=$PATH:$HOME/.cargo/bin
export RUST_SRC_PATH=~/.rustup/toolchains/stable-x86_64-apple-darwin/lib/rustlib/src/rust/src
export DYLD_LIBRARY_PATH=$DYLD_LIBRARY_PATH:$HOME/.rustup/toolchains/stable-x86_64-apple-darwin/lib

################## Node

export PATH=$PATH:$CODE/tern/bin
export PATH=$PATH:./node_modules/.bin

################# tmux

pair_program() {
  local session_name='pair'
  local tmux_socket='/tmp/tmux.socket'
  local client_count=$(tmux -S /tmp/tmux.socket list-clients | grep tty | wc -l | tr -d '[[:space:]]')

  if [[ $client_count == 0 ]]; then
    # cleanup code to remove socket as it will be stale and tmux gets confused.
    rm $tmux_socket
  fi

  if [[ ! -S $tmux_socket ]]; then
    # create a session through the socket in tmp, but do not attach
    tmux -S $tmux_socket new -s $session_name -d
  fi

  local socket_group=$(stat -f '%Sg' /tmp/tmux.socket)

  if [[ $socket_group != 'tmux' ]]; then
    # change the group so multiple users can connect
    chgrp tmux $tmux_socket
    chmod g+ws $tmux_socket
  fi

  # attach to session
  tmux -S $tmux_socket attach -t $session_name
}

################## Docker
docker_eval() {
  eval "$(docker-machine env default)"
}

################## Other

alias list_functions="print -l ${(ok)functions}"

# Sourcetree to path
alias stree=/Applications/SourceTree.app/Contents/Resources/stree

alias emacsapp="open $HB/usr/local/Cellar/emacs/24.4-dev/Emacs.app"

# ack 2.0 doesn't support searching all files, this does.
alias acka="ack --type-set='all:match:.*' -k"

# Virtualbox vm control
alias start_kernvm="VBoxManage startvm --type headless kernel_dev"
alias stop_kernvm="VBoxManage controlvm kernel_dev poweroff"
alias ssh_kernvm="ssh -p 2222 eric@127.0.0.1"

# shortcuts
# note: dropbox can contain spaces so we must wrap it in quotes
alias dreams="$EDITOR \"$DROPBOX/dreams.md\""
alias ideas="$EDITOR \"$DROPBOX/ideas.md\""
alias journal="$EDITOR \"$DROPBOX/journal.md\""
alias questions="$EDITOR \"$DROPBOX/questions.md\""
alias scratch="$EDITOR \"$DROPBOX/scratch.md\""
alias todo="$EDITOR \"$DROPBOX/todo.md\""

notes() {
  dir_fullpath=$(ls -d $DROPBOX/notes)
  paths=$(ls -t $DROPBOX/notes | fzf --multi)
  fullpaths=$(echo "$paths" | xargs -I "{}" echo "$dir_fullpath/{}")
  nvim $(echo "$fullpaths")
}

# android sdk
export ANDROID_HOME="$HB/opt/android-sdk"

# GPG default key
export GPGKEY=ED6BE39D

# swift repl
alias swift="xcrun --sdk iphonesimulator8.0 swift"

# fzf init
export FZF_DEFAULT_COMMAND='ag -g ""'
export FZF_DEFAULT_OPTS="--bind 'ctrl-a:toggle-all' --reverse --border --height=20 --history-size=10000"
if [ -e "$HB/opt/fzf/shell/completion.zsh" ]; then
  source "$HB/opt/fzf/shell/key-bindings.zsh"
  source "$HB/opt/fzf/shell/completion.zsh"
fi

# ripgrep
export RIPGREP_CONFIG_PATH="$HOME/.ripgreprc"

# ruby env home
export RBENV_ROOT="$HB/var/rbenv"
alias bundleinstall="bundle install --path .gems"

# To enable shims and autocompletion add to your profile:
if which rbenv > /dev/null; then eval "$(rbenv init -)"; fi

coffeeweb() {
  local startup_file=~/Desktop/snippets/web_repl_init.coffee
  local npath="${HOME}/code/web/app/client:${HOME}/code/web/app/assets/javascripts:${HOME}/code/web/vendor/components"

  NODE_PATH=$npath nesh -c -e $startup_file
}

# arcanist code review
if [[ -d $CODE/arcanist/bin ]]; then
   export PATH=$PATH:$CODE/arcanist/bin
   source $CODE/arcanist/resources/shell/bash-completion
fi

# fetches the patch files and patches directly in order specified
arcpatch_via_patch() {
  if [[ $# -lt 1 ]]; then
    echo arcpatch_via_patch [DIFF_ID...]
    return 1
  fi

  # loop over ids to find last.  Not sure of bash/zsh better way.
  for id in "$@"; do
    local last_id=$id
  done

  # name this branch using our last diff id
  git checkout -b "arcpatch-$last_id"

  # iterate over each diff file and patch
  for id in "$@"; do
    local patch_file=$(mktemp -t arcpatch)

    arc export --revision $id --git > "$patch_file"
    arc patch --nobranch --patch "$patch_file" --nocommit
    git add -A
    git commit -a -m "$id"
  done
}

# include scripts
export PATH=$PATH:$CODE/scripts

exit_if_failure() {
  exit_code=$?
  msg=${1:-BAD_EXIT_CODE}

  if [[ $exit_code != 0 ]]; then
    echo $msg
    exit $exit_code
  fi
}

# chrome
alias chrome="/Applications/Google\ Chrome.app/Contents/MacOS/Google\ Chrome"

############## FILE HELPERS

# search for a match and replace all matches with replacement
search_and_replace() {
  if [[ $# -lt 2 ]]; then
    echo search_and_replace PATTERN REPLACEMENT
    return 1
  fi

  local pattern=$1
  local replacement=$2

  # shift arguments twice, so that $@ will be empty or hold --filetype flags
  shift
  shift

  ag "$pattern" -l "$@" | xargs perl -pi -e "s/$pattern/$replacement/g"
}

############## GIT HELPERS

# modified files
alias modified_files="git ls-files -m -o -X .gitignore -X ~/.gitignore"

# find recent files committed
recent_changes() {
  # The parent branch/commit that we will eventually merge/rebase onto
  local default_parent=$(git mainbranch)
  local parent=${1:-$default_parent}
  local end_revision=${2:-HEAD}
  local start_revision=$(git merge-base $parent $end_revision)

  # used so that we can modify the paths and open recent changes no matter where we
  # are in the git tree
  # Will be '.' if we are at the root or `a/b/c`
  local root_path=$(git root -r)
  local slash_count=$(echo "$root_path" | tr -cd '/' | wc -c)
  local path_prefix=""
  for ((i=0; i<$slash_count; i++)); do
    path_prefix+="../"
  done

  # Get a list of all files ignoring deleted ones, and add the path prefix to each path
  git diff-tree --name-only -r --diff-filter=ACMT "${start_revision}..${end_revision}" | awk -v prefix="$path_prefix" '{print prefix $0}'
  git ls-files --others --exclude-standard | awk -v prefix="$path_prefix" '{print prefix $0}'
}

export CODE_BACKUP_DIR=$HOME/Dropbox/coding/backups

backup_branch() {
  #CODE_BACKUP_DIR must be defined

  local repo_name=$(basename $(git rev-parse --show-toplevel))
  local branch_name=$(git rev-parse --abbrev-ref HEAD)
  local now=$(date +'%Y%m%d_%H%M%s')
  local backup_dir="${CODE_BACKUP_DIR}/${repo_name}/${branch_name}/${branch_name}_${now}"
  local files_path=${backup_dir}/_files.txt

  mkdir -p $backup_dir

  local default_start_revision=$(git ancestor)
  local start_revision=${1:-$default_start_revision}
  local end_revision=${2:-$branch_name}

  # add revision numbers
  echo "START: $start_revision: $(git rev-parse $start_revision)" >> $files_path
  echo "END: $end_revision: $(git rev-parse $end_revision)" >> $files_path
  echo "--------------------------------------------------" >> $files_path

  # add changed files
  recent_changes $start_revision $end_revision >> $files_path
  modified_files >> $files_path
  sort -u -o $files_path $files_path

  # copy modified files
  rsync -a --ignore-missing-args --files-from=$files_path . $backup_dir

  # create git bundle backup.
  git bundle create "$backup_dir/backup.bundle" "$start_revision..$end_revision"
}

num_lines_changed() {
  local default_start_revision=$(git ancestor)
  local start_revision=${1:-$default_start_revision}
  local end_revision=${2:-HEAD}
  local add_sub_str=$(git diff --numstat $start_revision $end_revision | squeeze | cut -d' ' -f 1,2)
  local add_total=$(echo $add_sub_str | cut -d' ' -f 1 | paste -sd+ - | bc)
  local rm_total=$(echo $add_sub_str | cut -d' ' -f 2 | paste -sd+ - | bc)

  echo "ADDED: $add_total REMOVED: $rm_total"
}

# Joins args delimeter.
# Used to add '--or' in between params
# https://stackoverflow.com/questions/1527049/how-can-i-join-elements-of-an-array-in-bash
function join_by {
  local d=${1-} f=${2-}
  if shift 2; then
    printf %s "$f" "${@/#/$d}"
  fi
}

# grepAll PATTERN1, PATTERN2, ...
#
# Finds all files that contain all of the patterns even if they are on separate lines.
# Builds and runs a command like:
#   git grep --all-match -l -e 'PATTERN1' --or -e 'PATTERN2'
#
# NOTE: Only works within git repos
function grepAll() {
  local patterns=()
  for pattern in "$@"; do
    patterns+=("-e '$pattern'")
  done

  local joined_patterns=$(join_by ' --or ' "${patterns[@]}")

  local cmd="git --no-pager grep --all-match -l -E -i $joined_patterns"

  eval "$cmd"
}

############## AWS HELPERS

ec2_instances() {
  # Fetches EC2 instance info.
  #
  # ec2_instances --region us-east-1 $NAME 
  #
  # {
  #   "i-9e1dfa63": {
  #     "dns": "ec2-54-175-236-111.compute-1.amazonaws.com",
  #     "name": "logstash-02"
  #   },
  #   "i-9f1dfa62": {
  #     "dns": "ec2-54-175-242-4.compute-1.amazonaws.com",
  #     "name": "logstash-02"
  #   }
  # }
  
  # -D deletes options after using
  # -E changes the parsing rules to not stop at the first string that isn't described by one of the specs
  # -A stores results in associations
  # : means argument IS  mandatory
  # : means argument IS  mandatory
  # :: means argument IS NOT mandatory
  zparseopts -D -E -A ARGMAP -region:: r::=region

  # set region from --region, -r, or default
  region_default=us-east-1
  region=${ARGMAP[--region]:-${ARGMAP[-r]:-${region_default}}}

  local cmd='aws ec2 describe-instances --region ${region} --filters "Name=instance-state-name,Values=running"'
  local jqcmd="jq --sort-keys '.Reservations | map(.Instances) | flatten | map({key: .InstanceId, value: {name: .Tags[0].Value, dns: .PublicDnsName, private_dns: .PrivateDnsName, private_ip: .PrivateIpAddress, public_ip: .PublicIpAddress}}) | from_entries'"
  if [[ -n $1 ]]; then
    cmd="$cmd --filters 'Name=tag:Name,Values=*$1*'"
  fi

  eval $cmd | eval $jqcmd
} 

############## JQ HELPERS

# Find all unique json keys in a json file
jq_uniq_keys() {
  ftype=$(stat -f "%T" $stdin)
  if [[ "$ftype" != "|" ]]; then
     FILE=$1
  else
     FILE=${FILE:-/dev/stdin}
  fi

  cat $FILE | jq 'paths | map(.|tostring) | join(".")' | sed -E 's/\.[[:digit:]]+/.[]/g' | sort | uniq
}

### PROXY
# takes as argument "Wi-Fi" or "Thunderbolt Ethernet"
network_active() {
  # find ip address of network interface
  ip=$(networksetup -getinfo $1 | perl -l -ne '/^IP address: (.*)/ && print $1')

  # if ip exists
  if [[ -z "$ip" ]]; then
    # false
    return 1
  else
    # true
    return 0
  fi
}

tunnel_connection() {
  msg="$1"
  host="$2"

  is_ethernet=$(network_active "Thunderbolt Ethernet")
  if [[ is_ethernet == 0 ]]; then
    device="Thunderbolt Ethernet"
  else
    device="Wi-Fi"
  fi

  echo "Turning on proxy for ${device}"
  networksetup -setsocksfirewallproxystate "${device}" on

  echo "$msg"
  ssh -D 8080 -C -q -N "$host"

  echo "Turning off proxy"
  networksetup -setsocksfirewallproxystate "${device}" off
}

tunnel_csua() {
  tunnel_connection "Tunnelling to CSUA" "esiegel@csua.berkeley.edu"
}

tunnel_docean() {
  tunnel_connection "Tunnelling to DOCEAN" "root@docean"
}

############## DOCKER
docker_bash_latest() {
  image_id=$(docker images | tail -n+2 | head -n 1 | squeeze | cut -d ' ' -f 3)
  docker run -it ${image_id} /bin/bash
}

############## fnm

# nvm replacement for managing node envs
if command -v fnm >/dev/null 2>&1; then
  eval "$(fnm env --use-on-cd)"
fi

############## broot home
if command -v br >/dev/null 2>&1; then
  source "$HOME/.config/broot/launcher/bash/br"
fi

export PATH="$HOME/.yarn/bin:$HOME/.config/yarn/global/node_modules/.bin:$PATH"

############## java
export PATH="$HB/opt/openjdk/bin:$PATH"
export CPPFLAGS="-I$HB/opt/openjdk/include"

# >>> conda initialize >>>
# !! Contents within this block are managed by 'conda init' !!
__conda_setup="$("$HB/Caskroom/miniconda/base/bin/conda" 'shell.zsh' 'hook' 2> /dev/null)"
if [ $? -eq 0 ]; then
    eval "$__conda_setup"
else
    if [ -f "$HB/Caskroom/miniconda/base/etc/profile.d/conda.sh" ]; then
        . "$HB/Caskroom/miniconda/base/etc/profile.d/conda.sh"
    else
        export PATH="$HB/Caskroom/miniconda/base/bin:$PATH"
    fi
fi
unset __conda_setup
# <<< conda initialize <<<

############## memory improvements
# better process info
alias psx='ps xfo pid,etime,pcpu,rss:9,state,cmd'
alias psa='ps xafo pid,user:18,etime,pcpu,rss:9,state,cmd'

# Converts a JSON object with nestings into a flattened list.
# Nested paths become a.b.c
alias jq_struct='jq '"'"'select(objects)|=[.] | map( paths(scalars) ) | map( map(select(numbers)="[]") | join(".")) | unique'"'"

############## 1password cli

op_create_note_from_file() {
  local filepath="$1"
  local title="$2"
  local tags="$3"  # No default value; optional

  if [[ -z "$filepath" || -z "$title" ]]; then
    echo "Usage: op_create_note_from_file <filepath> <title> [tags]"
    return 1
  fi

  if [[ ! -f "$filepath" ]]; then
    echo "Error: File '$filepath' does not exist."
    return 1
  fi

  # Read file content
  local content
  content=$(cat "$filepath")

  if [[ -n "$tags" ]]; then
    op item create \
      --category='Secure Note' \
      --title="$title" \
      --tags "$tags" \
      notesPlain="$content" > /dev/null
  else
    op item create \
      --category='Secure Note' \
      --title="$title" \
      notesPlain="$content" > /dev/null
  fi
}

op_create_tmp_note_from_file() {
  local filepath="$1"
  local emails="$2"

  if [[ -z "$filepath" || -z "$emails" ]]; then
    echo "Usage: op_create_tmp_note_from_file <filepath> <emails>"
    return 1
  fi

  local title=$(sha256sum "$filepath" | cut -d ' ' -f 1)
  local tags=temporary

  # See if we have already created the note
  local found=$(
    op item list \
      --categories="Secure Note" \
      --tags="$tags" \
      --format=json | \
    jq --arg title "$title" '[.[] | select(.title == $title)] | length > 0'
  )

  if [[ "$found" == "true" ]]; then
    echo "Already created this note" >&2
    return 0
  else
    op_create_note_from_file "$filepath" "$title" "$tags"
  fi

  # create a temporary link
  op item share "$title" --expires-in "1h" --emails "$emails"
}

############## BUILD

export LDFLAGS="-L$HB/lib -L$HB/opt/zlib/lib -Wl,-rpath,$HB/opt/llvm/lib/c++"
export CFLAGS="-I$HB/include -I$HB/opt/zlib/include -Wno-enum-constexpr-conversion"
export CPPFLAGS="-I$HB/include -I$HB/opt/zlib/include -Wno-enum-constexpr-conversion"
export C_INCLUDE_PATH="$HB/include"

############## LLVM (clang)

# TODO ITK isn't building with clang 18 so we have this commented out
# We are ignoring `no-enum-constexpr-conversion` for now as ITK fail to compile with clang 16
# export PATH="$HB/opt/llvm/bin:$PATH"
# export LDFLAGS="-L$HB/lib -L$HB/opt/llvm/lib/c++ -L$HB/opt/zlib/lib -Wl,-rpath,$HB/opt/llvm/lib/c++"
# export CFLAGS="-I$HB/include -I$HB/opt/llvm/include -I$HB/opt/zlib/include -Wno-enum-constexpr-conversion"
# export CPPFLAGS="-I$HB/include -I$HB/opt/llvm/include -I$HB/opt/zlib/include -Wno-enum-constexpr-conversion"
# export C_INCLUDE_PATH="$HB/include:$HB/opt/llvm/include"
# export CPLUS_INCLUDE_PATH="$HB/include:$HB/opt/llvm/include"
# export CC="$HB/opt/llvm/bin/clang"
# export CXX="$HB/opt/llvm/bin/clang++"

# source $HOME/Library/Preferences/org.dystroy.broot/launcher/bash/br

# JAVA
# export PATH="$HB/opt/openjdk/bin:$PATH"
# export CPPFLAGS="-I$HB/opt/openjdk/include"
export PATH="/opt/homebrew/opt/libpq/bin:$PATH"

# Leave at the end and uncomment for profiling
# zprof
